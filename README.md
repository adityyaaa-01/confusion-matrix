# Confusion Matrix and Evaluation Metrics

This notebook is a practical revision of **classification model evaluation metrics**, including:

- 📊 Confusion Matrix  
- 🎯 Precision  
- 🔁 Recall  
- ⚖️ F1-Score  
- ✅ Accuracy  

## 🔍 Objective

Understand and implement the Confusion Matrix and use Scikit-learn's built-in functions to evaluate classification performance more effectively.

## 🧠 Concepts Covered

- What is a Confusion Matrix?
- Importance of Precision, Recall, and F1-Score
- When to use which metric?
- Visualizing model performance

## 🛠 Tools & Libraries

- Python
- Scikit-learn
- Matplotlib / Seaborn (if used for visualization)
- NumPy / Pandas

## 📂 Files

- `Confusion_Matrix(Precession,Recall,F1_score,Accuracy).ipynb` – Main notebook for evaluation metrics.

## 🚀 How to Run

1. Clone this repository
2. Install required packages (scikit-learn, matplotlib, etc.)
3. Open the notebook in Jupyter or Colab
4. Run all cells to see metric calculations and confusion matrix

---

**📌 Don't forget to star ⭐ the repository if you found it helpful!**
